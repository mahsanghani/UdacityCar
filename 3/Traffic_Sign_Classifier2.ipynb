{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import scipy.ndimage\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import sys\n",
    "# import tensorflow_addons as tfa\n",
    "# from tfa.layers import flatten\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_file = \"data/train.pickle\"\n",
    "validation_file= \"data/valid.pickle\"\n",
    "testing_file = \"data/test.pickle\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "\n",
    "assert(len(X_train) == len(y_train))\n",
    "assert(len(X_valid) == len(y_valid))\n",
    "assert(len(X_test) == len(y_test))\n",
    "\n",
    "print(\"X_train shape:\", X_train[0].shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_valid shape:\", X_valid[0].shape)\n",
    "print(\"y_valid shape:\", y_valid.shape)\n",
    "print(\"X_test shape:\", X_test[0].shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_train = len(X_train)\n",
    "n_valid = len(X_valid)\n",
    "n_test = len(X_test)\n",
    "image_shape = X_train[0].shape\n",
    "n_classes = len(np.unique(y_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Number of training examples = \", n_train)\n",
    "print(\"Number of validation example = \", n_valid)\n",
    "print(\"Number of testing samples = \", n_test)\n",
    "print(\"Shape of first training image = \", image_shape[0], \"w x\", image_shape[1], \"h x\", image_shape[2], \"d\")\n",
    "print(\"Number of classes = \", n_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "rand_train_indices = np.random.randint(0, X_train.shape[0], 10)\n",
    "rand_valid_indices = np.random.randint(0, X_valid.shape[0], 10)\n",
    "rand_test_indices = np.random.randint(0, X_test.shape[0], 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "for index in range(len(rand_train_indices)):\n",
    "    sub_plt = plt.subplot(2, 5, index + 1)\n",
    "    sub_plt.imshow(X_train[rand_train_indices[index]])\n",
    "    sub_plt.text(5, 5, y_train[rand_train_indices[index]], bbox=dict(facecolor='r', alpha=0.5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "for index in range(len(rand_valid_indices)):\n",
    "    sub_plt = plt.subplot(2, 5, index + 1)\n",
    "    sub_plt.imshow(X_valid[rand_valid_indices[index]])\n",
    "    sub_plt.text(5, 5, y_valid[rand_valid_indices[index]], bbox=dict(facecolor='y', alpha=0.5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "for index in range(len(rand_test_indices)):\n",
    "    sub_plt = plt.subplot(2, 5, index + 1)\n",
    "    sub_plt.imshow(X_test[rand_test_indices[index]])\n",
    "    sub_plt.text(5, 5, y_test[rand_test_indices[index]], bbox=dict(facecolor='g', alpha=0.5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "sub_plt = plt.subplot(3, 1, 1)\n",
    "train_hist = sub_plt.hist(y_train, bins=range(y_train.max() + 1))\n",
    "\n",
    "sub_plt = plt.subplot(3, 1, 2)\n",
    "valid_hist = sub_plt.hist(y_valid, bins=range(y_valid.max() + 1))\n",
    "\n",
    "sub_plt = plt.subplot(3, 1, 3)\n",
    "test_hist = sub_plt.hist(y_test, bins=range(y_test.max() + 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rand_train_ind = np.arange(X_train.shape[0])\n",
    "rand_valid_ind = np.arange(X_valid.shape[0])\n",
    "rand_test_ind = np.arange(X_test.shape[0])\n",
    "\n",
    "np.random.shuffle(rand_train_ind)\n",
    "np.random.shuffle(rand_valid_ind)\n",
    "np.random.shuffle(rand_test_ind)\n",
    "\n",
    "X_train = X_train[rand_train_ind].astype(np.float32)\n",
    "X_valid = X_valid[rand_valid_ind].astype(np.float32)\n",
    "X_test = X_test[rand_test_ind].astype(np.float32)\n",
    "\n",
    "y_train = y_train[rand_train_ind]\n",
    "y_valid = y_valid[rand_valid_ind]\n",
    "y_test = y_test[rand_test_ind]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train = (X_train - 128.0) / 128.0\n",
    "X_valid = (X_valid - 128.0) / 128.0\n",
    "X_test = (X_test - 128.0) / 128.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_oh_train = np.zeros((y_train.shape[0], y_train.max() + 1), dtype=np.float32)\n",
    "y_oh_train[np.arange(y_train.shape[0], dtype=np.uint32), y_train] = 1.0\n",
    "\n",
    "y_oh_valid = np.zeros((y_valid.shape[0], y_valid.max() + 1), dtype=np.float32)\n",
    "y_oh_valid[np.arange(y_valid.shape[0], dtype=np.uint32), y_valid] = 1.0\n",
    "\n",
    "y_oh_test = np.zeros((y_test.shape[0], y_test.max() + 1), dtype=np.float32)\n",
    "y_oh_test[np.arange(y_test.shape[0], dtype=np.uint32), y_test] = 1.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import sys"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Cnn5(object):\n",
    "\n",
    "    def __init__(self, features, filters, dense_size, num_out, nn_scope='CNN_Net'):\n",
    "\n",
    "        self._filters = filters\n",
    "        self._dense_size = dense_size\n",
    "        self._num_out = num_out\n",
    "        self._nn_scope = nn_scope\n",
    "\n",
    "        with tf.variable_scope(self._nn_scope):\n",
    "\n",
    "            self.conv_1 = tf.layers.conv2d(features, filters=self._filters[0], kernel_size=(3, 3),\n",
    "                                            strides=(1, 1), padding=\"VALID\",\n",
    "                                            kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                            bias_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                            activation=tf.nn.leaky_relu, name=\"Conv_1\")\n",
    "\n",
    "            self.conv_2 = tf.layers.conv2d(self.conv_1, filters=self._filters[1], kernel_size=(3, 3),\n",
    "                                            strides=(1, 1), padding=\"VALID\",\n",
    "                                            kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                            bias_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                            activation=tf.nn.leaky_relu, name=\"Conv_2\")\n",
    "\n",
    "            self.maxpool_1 = tf.layers.max_pooling2d(self.conv_2, pool_size=(2, 2), strides=(2, 2), name=\"MPool_1\")\n",
    "\n",
    "            self.conv_3 = tf.layers.conv2d(self.maxpool_1, filters=self._filters[2], kernel_size=(3, 3),\n",
    "                                            strides=(1, 1), padding=\"VALID\",\n",
    "                                            kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                            bias_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                            activation=tf.nn.leaky_relu, name=\"Conv_3\")\n",
    "\n",
    "            self.conv_4 = tf.layers.conv2d(self.conv_3, filters=self._filters[3], kernel_size=(3, 3),\n",
    "                                            strides=(1, 1), padding=\"VALID\",\n",
    "                                            kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                            bias_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                            activation=tf.nn.leaky_relu, name=\"Conv_4\")\n",
    "\n",
    "            self.maxpool_2 = tf.layers.max_pooling2d(self.conv_4, pool_size=(2, 2), strides=(2, 2), name=\"MPool_2\")\n",
    "\n",
    "\n",
    "            self.conv_5 = tf.layers.conv2d(self.maxpool_2, filters=self._filters[4], kernel_size=(3, 3),\n",
    "                                            strides=(1, 1), padding=\"VALID\",\n",
    "                                            kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                            bias_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                            activation=tf.nn.leaky_relu, name=\"Conv_5\")\n",
    "\n",
    "            self.flat = tf.layers.flatten(inputs=self.conv_5, name=\"Flat_Conv_5\")\n",
    "\n",
    "            self.fc_1 = tf.layers.dense(self.flat, units=self._dense_size[0],\n",
    "                                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                         bias_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                         activation=tf.nn.leaky_relu, name=\"FC_1\")\n",
    "\n",
    "            self.fc_2 = tf.layers.dense(self.fc_1, units=self._dense_size[1],\n",
    "                                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                         bias_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                         activation=tf.nn.leaky_relu, name=\"FC_2\")\n",
    "\n",
    "            self.logits = tf.layers.dense(self.fc_2, units=self._num_out,\n",
    "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           bias_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           name=\"Logits\")\n",
    "\n",
    "            self.prediction = tf.nn.softmax(self.logits)\n",
    "\n",
    "            self.output = tf.argmax(self.logits, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filters = [16, 24, 48, 64, 128]\n",
    "dense_size = [384, 256]\n",
    "\n",
    "with tf.variable_scope('Placeholders'):\n",
    "    # Lets define the requied placeholders\n",
    "    features = tf.placeholder(tf.float32, shape=[None] + list(image_shape), name=\"Features\")\n",
    "    labels = tf.placeholder(dtype=tf.float32, shape=[None] + list(y_oh_train.shape[1:]), name=\"Labels\")\n",
    "    learning_rate = tf.placeholder(dtype=tf.float32, name=\"Learning_rate\")\n",
    "\n",
    "\n",
    "# Using these placeholders, lets construct our Neural Network\n",
    "cnn5 = Cnn5(features, filters, dense_size, labels.shape[1])\n",
    "# Now lets define the cost\n",
    "with tf.variable_scope('Cost'):\n",
    "    entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=cnn5.logits, labels=labels, name='loss')\n",
    "    cost_t = tf.reduce_mean(entropy)\n",
    "# Accuracy may help us evaluate our training better:\n",
    "with tf.variable_scope('Accuracy'):\n",
    "    correct_preds = tf.equal(cnn5.output, tf.argmax(labels, 1))\n",
    "    accuracy_t = tf.reduce_mean(tf.cast(correct_preds, tf.float32))\n",
    "# Finally define the optimizer:\n",
    "with tf.variable_scope('Optimizer'):\n",
    "    optimize_t = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost_t)\n",
    "writer_train = tf.summary.FileWriter(\"./tensorboard/\", graph=tf.get_default_graph())\n",
    "writer_train.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "# Definition of One Epoch of training\n",
    "def train_epoch(epoch, rate):\n",
    "\n",
    "    prog_bar = tqdm(desc=\"Train Epoch %d\" % epoch, total=n_train)\n",
    "\n",
    "    error_list, accuracy_list = [], []\n",
    "    low, high, step_size, end = 0, n_train + 1, BATCH_SIZE, 0\n",
    "\n",
    "    for start, end in zip(range(low, high, step_size), range(low + step_size, high, step_size)):\n",
    "        _, error, accuracy = sess.run([optimize_t, cost_t, accuracy_t],\n",
    "            feed_dict={features: X_train[start:end],labels: y_oh_train[start:end],learning_rate: rate})\n",
    "\n",
    "        prog_bar.set_postfix_str(\"Cost: %f, Acc: %f\" % (error, accuracy), refresh=True)\n",
    "        prog_bar.update(n=BATCH_SIZE)\n",
    "        error_list.append(error)\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "    error = sum(error_list) / len(error_list)\n",
    "    accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "    prog_bar.set_postfix_str(\"Cost: %f, Acc: %f\" % (error, accuracy), refresh=True)\n",
    "    prog_bar.close()\n",
    "    sys.stdout.flush()\n",
    "    return error, accuracy\n",
    "sess_config = tf.ConfigProto(device_count={'GPU': 1})\n",
    "sess_config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=sess_config)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Start the training\n",
    "for index in range(NUM_EPOCHS // 2):\n",
    "    train_epoch(index + 1, LEARNING_RATE)\n",
    "\n",
    "for index in range(NUM_EPOCHS // 2, NUM_EPOCHS):\n",
    "    error, accuracy = train_epoch(index + 1, LEARNING_RATE / 2)\n",
    "\n",
    "saver.save(sess, './saved_models/lane')\n",
    "sess.close()\n",
    "\n",
    "print(\"Final Epoch Cost: %f, Final Epoch Accuracy: %f\" %(error, accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def valid_epoch(epoch):\n",
    "\n",
    "    prog_bar = tqdm(desc=\"Valid Epoch %d\" % epoch, total=n_validation)\n",
    "\n",
    "    error_list, accuracy_list = [], []\n",
    "    low, high, step_size, end = 0, n_validation + 1, BATCH_SIZE, 0\n",
    "\n",
    "    for start, end in zip(range(low, high, step_size), range(low + step_size, high, step_size)):\n",
    "        error, accuracy = sess.run([cost_t, accuracy_t],\n",
    "            feed_dict={features: X_valid[start:end],labels: y_oh_valid[start:end]})\n",
    "\n",
    "        prog_bar.set_postfix_str(\"Cost: %f, Acc: %f\" % (error, accuracy), refresh=True)\n",
    "        prog_bar.update(n=BATCH_SIZE)\n",
    "        error_list.append(error)\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "    error = sum(error_list) / len(error_list)\n",
    "    accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "    prog_bar.set_postfix_str(\"Cost: %f, Acc: %f\" % (error, accuracy), refresh=True)\n",
    "    prog_bar.close()\n",
    "    sys.stdout.flush()\n",
    "    return error, accuracy\n",
    "# Start the validation\n",
    "sess = tf.Session(config=sess_config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.restore(sess, tf.train.latest_checkpoint('./saved_models/'))\n",
    "error, accuracy = valid_epoch(1)\n",
    "sess.close()\n",
    "print(\"Validation Epoch Cost: %f, Validation Epoch Accuracy: %f\" %(error, accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_epoch(epoch):\n",
    "\n",
    "    prog_bar = tqdm(desc=\"Test Epoch %d\" % epoch, total=n_test)\n",
    "\n",
    "    error_list, accuracy_list = [], []\n",
    "    low, high, step_size, end = 0, n_test + 1, BATCH_SIZE, 0\n",
    "\n",
    "    for start, end in zip(range(low, high, step_size), range(low + step_size, high, step_size)):\n",
    "        error, accuracy = sess.run([cost_t, accuracy_t],\n",
    "            feed_dict={features: X_test[start:end],labels: y_oh_test[start:end]})\n",
    "\n",
    "        prog_bar.set_postfix_str(\"Cost: %f, Acc: %f\" % (error, accuracy), refresh=True)\n",
    "        prog_bar.update(n=BATCH_SIZE)\n",
    "        error_list.append(error)\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "    error = sum(error_list) / len(error_list)\n",
    "    accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "    prog_bar.set_postfix_str(\"Cost: %f, Acc: %f\" % (error, accuracy), refresh=True)\n",
    "    prog_bar.close()\n",
    "    sys.stdout.flush()\n",
    "    return error, accuracy\n",
    "# Start the testing\n",
    "sess = tf.Session(config=sess_config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.restore(sess, tf.train.latest_checkpoint('./saved_models/'))\n",
    "error, accuracy = test_epoch(1)\n",
    "sess.close()\n",
    "print(\"Test Epoch Cost: %f, Test Epoch Accuracy: %f\" %(error, accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2\n",
    "from glob import glob\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "# Now lets read the image paths from the file system. These images are part of the test dataset of GTSRB.\n",
    "image_paths = glob('./gtsrb_test_data/*.png')\n",
    "\n",
    "images = []\n",
    "for img_path in image_paths:\n",
    "    img = mpimg.imread(img_path)\n",
    "    resized_img = cv2.resize(img, (32, 32))\n",
    "    images.append(resized_img)\n",
    "\n",
    "# Lets Visualize some random samples from the test dataset\n",
    "plt.figure(figsize=(16, 5))\n",
    "for index in range(len(images)):\n",
    "    sub_plt = plt.subplot(2, 5, index + 1)\n",
    "    sub_plt.imshow(images[index])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true_labels = np.array([2, 18, 1, 14, 12, 5, 3, 36, 33, 4])\n",
    "\n",
    "# Start the testing\n",
    "sess = tf.Session(config=sess_config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.restore(sess, tf.train.latest_checkpoint('./saved_models/'))\n",
    "\n",
    "[output] = sess.run([cnn5.output], feed_dict={features: images})\n",
    "sess.close()\n",
    "\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy = np.mean(np.equal(true_labels, output)) * 100\n",
    "print(\"Performance is %f \" % accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sess = tf.Session(config=sess_config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.restore(sess, tf.train.latest_checkpoint('./saved_models/'))\n",
    "\n",
    "top_5_prob = tf.nn.top_k(cnn5.prediction, k=5)\n",
    "\n",
    "top_prob = sess.run(top_5_prob, feed_dict={features: images})\n",
    "sess.close()\n",
    "\n",
    "print(top_prob)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def outputFeatureMap(image_input, tf_activation, activation_min=-1, activation_max=-1 ,plt_num=1):\n",
    "    # Here make sure to preprocess your image_input in a way your network expects\n",
    "    # with size, normalization, ect if needed\n",
    "    # image_input =\n",
    "    # Note: x should be the same name as your network's tensorflow data placeholder variable\n",
    "    # If you get an error tf_activation is not defined it may be having trouble accessing the variable from inside a function\n",
    "    activation = tf_activation.eval(session=sess,feed_dict={x : image_input})\n",
    "    featuremaps = activation.shape[3]\n",
    "    plt.figure(plt_num, figsize=(15,15))\n",
    "    for featuremap in range(featuremaps):\n",
    "        plt.subplot(6,8, featuremap+1) # sets the number of feature maps to show on each row and column\n",
    "        plt.title('FeatureMap ' + str(featuremap)) # displays the feature map number\n",
    "        if activation_min != -1 & activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin =activation_min, vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_min !=-1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin=activation_min, cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", cmap=\"gray\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
